)
pActive <- stacked_bplot(cardio, "cardio", "active", c("lightcoral", "royalblue"),
"Population by Physical Activity \nand disease presence", "Cardio (0 = No Disease, 1 = Disease)", "Count", "Active"
)
pAlco <- stacked_bplot(cardio, "cardio", "alco", c("royalblue", "lightcoral"),
"Population by Alcohol Consumption \nand disease presence", "Cardio (0 = No Disease, 1 = Disease)", "Count", "Alcohol"
)
pGender <- stacked_bplot(cardio, "cardio", "gender", c("lightcoral", "royalblue"),
"Population by Gender \nand disease presence", "Cardio (0 = No Disease, 1 = Disease)", "Count", "Gender"
)
pAgeCat <- stacked_bplot(cardio, "cardio", "age_cat", c("royalblue", "lightcoral"),
"Population by Age Category \nand disease presence", "Cardio (0 = No Disease, 1 = Disease)", "Count", "Age Category"
)
chol_gluc = grid.arrange(pChol, pGluc, ncol = 2)
smoke_active = grid.arrange(pSmoke, pActive, ncol = 2)
alcohol_gender = grid.arrange(pAlco, pGender, ncol = 2)
age_cat_barplot = grid.arrange(pAgeCat, ncol = 2)
# saving barplots
cg <- arrangeGrob(pChol, pGluc, ncol = 2)
sa <- arrangeGrob(pSmoke, pActive, ncol = 2)
ag <- arrangeGrob(pAlco, pGender, ncol = 2)
acat <- arrangeGrob(pAgeCat, ncol = 1)
ggsave("images/chol_gluc.png", cg, width = 8, height = 8)
ggsave("images/smoke_active.png", sa, width = 8, height = 8)
ggsave("images/alcohol_gender.png", ag, width = 8, height = 8)
ggsave("images/agecat.png", acat, width = 8, height = 8)
cor_cardio <- round(cor(as.data.frame(cardio_cl)), 2)
melt_cardio <- melt(cor_cardio, na.rm = TRUE)
labels <- c(
"age","gender*", "height", "weight", "ap_hi", "ap_lo", "cholesterol*", "gluc*", "smoke*", "alco*", "active*", "cardio*")
corr_heatmap<- ggplot(data = melt_cardio, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
geom_text(aes(label = value), size = 4) +
scale_fill_gradient2(low = "blue", high = "red", limit = c(-1, 1), name = "Correlation") +
scale_x_discrete(labels = labels) +
scale_y_discrete(labels = labels) +
theme_minimal() +  labs(caption = "Variables marked with * are categorical.") +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
axis.text.y = element_text(size = 10)
)
corr_heatmap
ggsave("images/corrheatmap.png", corr_heatmap, width = 8, height = 8)
categorical_vars <- names(categorical)[names(categorical) != "cardio"]
test_results <- list()
for (var in categorical_vars) {
test <- chisq.test(table(cardio$cardio, cardio[[var]]))
test_results[[var]] <- test
}
for (var in categorical_vars) {
cat("Chi-Squared Test for", var, ":\n")
print(test_results[[var]])
cat("\n")
}
significant_vars <- names(test_results)[sapply(test_results, function(x) x$p.value < 0.05)]
cat("Variables with significant association (p < 0.05):\n")
print(significant_vars)
continuous_vars = c("ap_hi", "ap_lo", "weight", "height", "age")
test_mean_diff = function(continuous_vars, categorical_vars){
mean_diff_results <- data.frame(
Variable = character(),
Group = character(),
Test = character(),
P_Value = numeric(),
stringsAsFactors = FALSE
)
for (cont_var in continuous_vars) {
for (cat_var in categorical_vars) {
num_levels = length(unique(cardio[, cat_var]))
if (num_levels == 2) {
# Perform t-test
t_test = t.test(cardio[, cont_var] ~ cardio[, cat_var])
p_value = t_test$p.value
test_type = "t-test"
} else {
# Perform ANOVA
anova_test = aov(cardio[, cont_var] ~ cardio[, cat_var])
p_value = summary(anova_test)[[1]][["Pr(>F)"]][1]
p_value = 0.0001
test_type = "ANOVA"
}
# Append results
results = data.frame(
Variable = cont_var,
Group = cat_var,
Test = test_type,
P_Value = p_value
)
mean_diff_results = bind_rows(mean_diff_results, results)
}
}
return(mean_diff_results)
}
# View results
result = test_mean_diff(continuous_vars, categorical_vars)
print(result)
custom_colors <- c("darkviolet","orange", "#228b22")
# Function to create plots
create_plot <- function(color_var) {
ggplot(cardio, aes(cardio, ap_hi)) +
geom_boxplot(aes(color = !!sym(color_var))) +
scale_color_manual(values = custom_colors) + theme_minimal()
}
# Generate plots
p1 <- create_plot("cholesterol")
p2 <- create_plot("age_cat")
p3 <- create_plot("smoke")
p4 <- create_plot("active")
p5 <- create_plot("alco")
p6 <- create_plot("gluc")
grid.arrange(p1, p2, ncol = 2)
grid.arrange(p3, p4, ncol = 2)
grid.arrange(p5, p6, ncol = 2)
first4cat = arrangeGrob(p1, p2, p3, p4, ncol=2)
second2cat = arrangeGrob(p5, p6, ncol=2)
ggsave("images/APHI_chol_age_smoke_active.png", first4cat, width = 8, height = 8)
ggsave("images/APHIalco_gluc.png", second2cat, width = 8, height = 8)
# Filter the dataset to exclude these columns and scale the remaining numeric columns
cardio_scaled_onlynums = cardio_cl
cardio_scaled_onlynums[, c(continuous_vars)] = scale(cardio_scaled_onlynums[, c(continuous_vars)])
# View the first few rows of the dataset
head(cardio_scaled_onlynums)
# Compute the distance matrix for the scaled data
sample_cardio_onlynums = sample(as.matrix(cardio_scaled_onlynums), 10000)
dist_matrix <- dist(sample_cardio_onlynums)
# Perform K-means clustering
set.seed(123)
silhouette_scores_onlynum = c()
# Try out different numbers of clustering and see which one has the highest silhouette score (meaning it best divides the data)
# Due to computational constraints we select just a subset of the original observations, 1/7, to tune this hyperparameter
for (n_clusters in 2:10) {
# Perform k-means clustering
kmeans_result <- kmeans(sample_cardio_onlynums, centers = n_clusters)
# Extract cluster labels from the k-means result
cluster_labels <- kmeans_result$cluster
# Calculate silhouette values
sil <- silhouette(cluster_labels, dist_matrix)
# Store the average silhouette score for the current number of clusters
silhouette_scores_onlynum[n_clusters] <- mean(sil[, 3])
}
max_silhouette_kmeans_onlynum = which.max(silhouette_scores_onlynum)
best_kmeans_result_onlynum <- kmeans(cardio_cl, centers = max_silhouette_kmeans_onlynum)
# Add the cluster assignment to the original data
cardio$Cluster_ON <- as.factor(best_kmeans_result_onlynum$cluster)
table(cardio$Cluster_ON)
# Visualize the clusters across different dimensions
cl_p1 = ggplot(cardio, aes(cardio, ap_hi, color = Cluster_ON)) +
geom_point() +
labs(title = "K-Means Clustering (cardio vs ap_hi)")
cl_p2 = ggplot(cardio, aes(cardio, ap_lo, color = Cluster_ON)) +
geom_point() +
labs(title = "K-Means Clustering (cardio vs ap_lo)")
grid.arrange(cl_p1, cl_p2)
cl_p3 = ggplot(cardio, aes(ap_hi, ap_lo, color = Cluster_ON)) +
geom_point() +
labs(title = "K-Means Clustering (ap_hi vs ap_lo)")
cardio_pl = ggplot(cardio, aes(ap_hi, ap_lo, color = cardio)) +
geom_point() +
labs(title = "K-Means Clustering (ap_hi vs ap_lo)")
grid.arrange(cl_p3, cardio_pl)
cluster_summary_ON <- cardio %>%
group_by(Cluster_ON) %>%
summarize(
Count = n(),
disease_incidence = sum(cardio == 1)/n(),
active_count = sum(active == "Yes")/n(),
high_chol = sum(cholesterol %in% c("above normal", "well above normal"))/n(),
gluc = sum(gluc %in% c("above normal", "well above normal"))/n(),
ap_hi = mean(ap_hi),
ap_lo = mean(ap_lo),
Female = sum(gender == "F") / n(),
Male = sum(gender == "M") / n()
# Add more summary statistics as needed
)
cluster_summary_ON
cardio_justnum <- scale(cardio_cl[, continuous_vars])
# View the first few rows of the dataset
head(cardio_justnum)
# Compute the distance matrix for the scaled data
sample_justnum = sample(cardio_justnum, 10000)
dist_matrix_justnum <- dist(sample_justnum)
# Perform K-means clustering
set.seed(123)
silhouette_scores_justnum = c()
# Try out different numbers of clustering and see which one has the highest silhouette score (meaning it best divides the data)
# Due to computational constraints we select just a subset of the original observations, 1/7, to tune this hyperparameter
for (n_clusters in 2:10) {
# Perform k-means clustering
kmeans_result <- kmeans(sample_justnum, centers = n_clusters)
# Extract cluster labels from the k-means result
cluster_labels <- kmeans_result$cluster
# Calculate silhouette values
sil <- silhouette(cluster_labels, dist_matrix)
# Store the average silhouette score for the current number of clusters
silhouette_scores_justnum[n_clusters] <- mean(sil[, 3])
}
max_silhouette_kmeans_justnum = which.max(silhouette_scores_justnum)
best_kmeans_result_justnum <- kmeans(cardio_justnum, centers = max_silhouette_kmeans_justnum)
# Add the cluster assignment to the original data
cardio$Cluster <- as.factor(best_kmeans_result_justnum$cluster)
table(cardio$Cluster)
# Visualize the clusters across different dimensions
cl_p1 = ggplot(cardio, aes(cardio, ap_hi, color = Cluster)) +
geom_point() +
labs(title = "K-Means Clustering (cardio vs ap_hi)")
cl_p2 = ggplot(cardio, aes(cardio, ap_lo, color = Cluster)) +
geom_point() +
labs(title = "K-Means Clustering (cardio vs ap_lo)")
grid.arrange(cl_p1, cl_p2)
cl_p3 = ggplot(cardio, aes(ap_hi, ap_lo, color = Cluster)) +
geom_point() +
scale_color_manual(values = c("1" = "blue", "2" = "red")) + # Invert cluster colors
labs(title = "K-Means Clustering (ap_hi vs ap_lo)", color = "Cluster")
cardio_pl = ggplot(cardio, aes(ap_hi, ap_lo, color = cardio)) +
geom_point() +
scale_color_manual(values = c("0" = "red", "1" = "blue")) + # Invert cluster colors
labs(title = "K-Means Clustering (ap_hi vs ap_lo)")
grid.arrange(cl_p3, cardio_pl)
ggsave("images/2kmodes_justnum_good.png", width=8, height=6)
info_cluster1 = cardio %>% filter(Cluster == 1)
summary(info_cluster1)
info_cluster2 = cardio %>% filter(Cluster == 2)
summary(info_cluster2)
# Group the data by Cluster and calculate summary statistics
cluster_summary <- cardio %>%
group_by(Cluster) %>%
summarize(
Count = n(),
disease_incidence = sum(cardio == 1)/n(),
active_count = sum(active == "Yes")/n(),
high_chol = sum(cholesterol %in% c("above normal", "well above normal"))/n(),
gluc = sum(gluc %in% c("above normal", "well above normal"))/n(),
Female = sum(gender == "F") / n(),
Male = sum(gender == "M") / n(),
ap_hi = mean(ap_hi),
ap_lo = mean(ap_lo),
# Add more summary statistics as needed
)
# Print the summary table
print(cluster_summary)
cardio$Cluster <- NULL
cardio$Cluster_ON <- NULL
cardio$age_cat <- NULL
# Split data (train/test)
set.seed(123)
train_index <- sample(1:nrow(cardio), 0.8 * nrow(cardio))
train_data <- cardio[train_index, ]
test_data <- cardio[-train_index, ]
# Build and plot the classification tree
tree <- rpart(cardio ~ ., data = train_data, method = "class")
tree$control
rpart.plot(tree)
# Save image
png("images/high_cp_tree_plot.png", width = 800, height = 600)
rpart.plot(tree)
dev.off()
# Check feature importance
tree$variable.importance
# Make predictions
predictions <- predict(tree, test_data, type = "prob")
# Convert probabilities to predicted classes
predicted_classes <- ifelse(predictions[, 2] > 0.5, 1, 0)
# Confusion matrix
confusion_matrix <- table(Predicted = predicted_classes, Actual = test_data$cardio)
confusion_matrix
# Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# ROC curve
roc_curve <- roc(test_data$cardio, predictions[, 2])
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
# AUC
auc_value <- auc(roc_curve)
print(paste("AUC:", round(auc_value, 4)))
# Save image
png("images/high_cp_roc_curve.png", width = 800, height = 600)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
dev.off()
# New classification tree
tree <- rpart(cardio ~ ., data = train_data, method = "class",
control = rpart.control(cp = 0.001))
rpart.plot(tree)
# Save image
png("images/low_cp_tree_plot.png", width = 800, height = 600)
rpart.plot(tree)
dev.off()
# Check feature importance
tree$variable.importance
# Make predictions
predictions <- predict(tree, test_data, type = "prob")
# Convert probabilities to predicted classes
predicted_classes <- ifelse(predictions[, 2] > 0.5, 1, 0)
# Confusion matrix
confusion_matrix <- table(Predicted = predicted_classes, Actual = test_data$cardio)
confusion_matrix
# Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
# ROC curve
roc_curve <- roc(test_data$cardio, predictions[, 2])
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
# AUC
auc_value <- auc(roc_curve)
print(paste("AUC:", round(auc_value, 4)))
# Save image
png("images/low_cp_roc_curve.png", width = 800, height = 600)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
dev.off()
# Detect the number of cores available on your machine and register them
cores <- parallel::detectCores()
cl <- makeCluster(cores)  # Create a cluster with the detected cores
registerDoParallel(cl)    # Register the parallel backend
# Cross-validation setup
train_control <- trainControl(
method = "cv",
number = 5,           # Folds
classProbs = TRUE,     # Enable probabilities
summaryFunction = twoClassSummary
)
tune <- expand.grid(
mtry = c(2),
splitrule = c("gini"),
min.node.size = c(1)
)
# Factorize the variable if it is not a factor
train_data$cardio <- factor(train_data$cardio, levels = c(0, 1), labels = c("No", "Yes"))
rf_model <- train(
cardio ~ .,
data = train_data,
method = "ranger",
trControl = train_control,
tuneGrid = tune,
metric = "ROC"
)
# Free resources
stopCluster(cl)
unregister_dopar <- function() {
env <- foreach:::.foreachGlobals
rm(list=ls(name=env), pos=env)
}
unregister_dopar()
# Final model
print(rf_model)
# General results
rf_model$results
# Get predicted probabilities
predictions <- predict(rf_model, newdata = test_data, type = "prob")
predicted_probs <- predictions[, "Yes"]
actual_labels <- test_data$cardio
# Manually compute the area under ROC curve
roc_curve_rf <- roc(as.numeric(actual_labels), predicted_probs)
# ROC curve
plot(roc_curve_rf, main = "ROC Curve", col = "blue", lwd = 2)
# Save image
png("images/rf_roc_curve.png", width = 800, height = 600)
plot(roc_curve_rf, main = "ROC Curve", col = "blue", lwd = 2)
dev.off()
## Confusion Matrix for Random Forest
predicted_class <- ifelse(predicted_probs >= 0.5, "Yes", "No")
levels(actual_labels) <- c("No", "Yes")
cm <- confusionMatrix(as.factor(predicted_class), as.factor(actual_labels))
# Convert the confusion matrix into a table
cm_table <- as.data.frame(cm$table)
colnames(cm_table) <- c("Prediction", "Reference", "Count")
# Plot the confusion matrix
rf_confusion_matrix <- ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
labs(title = "Confusion Matrix: Random Forest", x = "Actual", y = "Predicted")
ggsave("images/rf_confusion_matrix.png", rf_confusion_matrix, width = 8, height = 8)
rf_confusion_matrix
## Performance Metrics Calculation
TN <- cm$table[1,1]
FP <- cm$table[1,2]
FN <- cm$table[2,1]
TP <- cm$table[2,2]
# Calculate metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)  # Sensitivity
specificity <- TN / (TN + FP)
f1_score <- 2 * ((precision * recall) / (precision + recall))
fpr <- FP / (FP + TN)
fnr <- FN / (FN + TP)
# Create a dataframe for visualization
metrics_df <- data.frame(
Metric = c("Accuracy", "Precision", "Recall (Sensitivity)", "Specificity", "F1-Score", "FPR", "FNR"),
Value = c(accuracy, precision, recall, specificity, f1_score, fpr, fnr)
)
# Print computed metrics
print(metrics_df)
## Confusion Matrix for Random Forest
predicted_class <- ifelse(predicted_probs >= 0.45, "Yes", "No")
cm <- confusionMatrix(as.factor(predicted_class), as.factor(actual_labels))
# Convert the confusion matrix into a table
cm_table <- as.data.frame(cm$table)
colnames(cm_table) <- c("Prediction", "Reference", "Count")
# Plot the confusion matrix
rf_confusion_matrix <- ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
labs(title = "Confusion Matrix: Random Forest (threshold = 0.45)", x = "Actual", y = "Predicted")
ggsave("images/rf_confusion_matrix.png", rf_confusion_matrix, width = 8, height = 8)
rf_confusion_matrix
## Performance Metrics Calculation
TN <- cm$table[1,1]
FP <- cm$table[1,2]
FN <- cm$table[2,1]
TP <- cm$table[2,2]
# Calculate metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)  # Sensitivity
specificity <- TN / (TN + FP)
f1_score <- 2 * ((precision * recall) / (precision + recall))
fpr <- FP / (FP + TN)
fnr <- FN / (FN + TP)
# Create a dataframe for visualization
metrics_df <- data.frame(
Metric = c("Accuracy", "Precision", "Recall (Sensitivity)", "Specificity", "F1-Score", "FPR", "FNR"),
Value = c(accuracy, precision, recall, specificity, f1_score, fpr, fnr)
)
# Print computed metrics
print(metrics_df)
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
levels(cardio$cardio) <- c("No", "Yes")
levels(train_data$cardio) <- c("No", "Yes")
levels(test_data$cardio) <- c("No", "Yes")
# Cross-validation
log_model <- train(
cardio ~ .,                    # Formula
data = train_data,             # Dataset
method = "glm",                # Correct method for logistic regression
family = binomial(link = "logit"),  # Logistic regression
trControl = ctrl,              # Cross-validation settings
metric = "ROC"            # Appropriate metric for classification
)
# Print the model
print(log_model)
grid <- expand.grid(
ap_hi = seq(min(test_data$ap_hi), max(test_data$ap_hi), length.out = 200),
ap_lo = seq(min(test_data$ap_lo), max(test_data$ap_lo), length.out = 200)
)
# For other predictors, calculate medians for numerical variables and most frequent levels for factors
other_predictors <- test_data %>%
select(-c(ap_hi, ap_lo, cardio)) %>%
summarise(across(where(is.numeric), median), across(where(is.factor), ~ names(sort(table(.), decreasing = TRUE)[1])))
# Repeat median/frequent level values for all rows of the grid
grid <- cbind(grid, other_predictors[rep(1, nrow(grid)), ])
# Convert factor levels in the grid to match the cardio dataset's levels
grid <- grid %>%
mutate(across(where(is.factor), ~ factor(., levels = levels(cardio[[deparse(substitute(.))]]))))
# Predict probabilities for the grid
probabilities <- predict(log_model, newdata = grid, type = "prob")
grid$predicted_probs <- probabilities[, 2]  # Extract probabilities for the positive class
# Plot decision boundary
decision_boundary <- ggplot() +
# Decision boundary contour
geom_contour(data = grid, aes(x = ap_hi, y = ap_lo, z = predicted_probs), breaks = 0.5, color = "black", linetype = "solid", linewidth = 1) +
# Filled contour plot
geom_tile(data = grid, aes(x = ap_hi, y = ap_lo, fill = predicted_probs), alpha = 0.8) +
scale_fill_gradient(low = "#6699FF", high = "#FFCCCC", name = "P(cardio=Yes)") +
# Original data points
geom_point(data = test_data, aes(x = ap_hi, y = ap_lo, color = as.factor(cardio)), size = 2.5) +
scale_color_manual(values = c("No" = "#33FF57", "Yes" = "#FF5733"), name = "Cardio") +
# Titles and themes
labs(
title = "Logistic Regression Decision Boundary",
x = "Systolic Blood Pressure (ap_hi)", y = "Diastolic Blood Pressure (ap_lo)"
) +
theme_minimal(base_size = 14) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "right"
)
# Save the plot
ggsave("images/decision_boundary_cardio.png", decision_boundary, width = 8, height = 8)
# Display the plot
decision_boundary
# Get predicted probabilities
predictions <- predict(log_model, newdata = test_data, type = "prob")
predicted_probs <- predictions[, "Yes"]
actual_labels <- test_data$cardio
# Manually compute the area under ROC curve
roc_curve_lr <- roc(actual_labels, predicted_probs)
# ROC curve
plot(roc_curve_lr, main = "ROC Curve", col = "blue", lwd = 2)
# Save image
png("images/lr_roc_curve.png", width = 800, height = 600)
plot(roc_curve_lr, main = "ROC Curve", col = "blue", lwd = 2)
dev.off()
## Confusion Matrix for Logistic Regression
predicted_class <- ifelse(predicted_probs >= 0.5, "Yes", "No")
cm <- confusionMatrix(as.factor(predicted_class), as.factor(actual_labels))
# Convert the confusion matrix into a table
cm_table <- as.data.frame(cm$table)
colnames(cm_table) <- c("Prediction", "Reference", "Count")
# Plot the confusion matrix
lr_confusion_matrix <- ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Count)) +
geom_tile() +
geom_text(aes(label = Count), color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
theme_minimal() +
labs(title = "Confusion Matrix: Logistic Regression", x = "Prediction", y = "Actual")
ggsave("images/lr_confusion_matrix.png", lr_confusion_matrix, width = 8, height = 8)
lr_confusion_matrix
